{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data wrangling project\n",
    "\n",
    "### Context\n",
    "Wrangle [WeRateDogs](https://twitter.com/dog_rates) Twitter data to create interesting and trustworthy analyses and visualizations. The Twitter archive is great, but it only contains very basic tweet information. Additional gathering, then assessing and cleaning is required for \"Wow!\"-worthy analyses and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import tweepy\n",
    "import json\n",
    "\n",
    "import twitter_credetials as twc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter = pd.read_csv('twitter-archive-enhanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "\n",
    "response = requests.get(url)\n",
    "with open('image_predictions.tsv', mode='wb') as file:\n",
    "        file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prd = pd.read_csv('image_predictions.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(twc.consumer_key, twc.consumer_secret)\n",
    "auth.set_access_token(twc.access_token, twc.access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No status found with that ID. : 888202515573088257\n",
      "No status found with that ID. : 873697596434513921\n",
      "No status found with that ID. : 872668790621863937\n",
      "No status found with that ID. : 872261713294495745\n",
      "No status found with that ID. : 869988702071779329\n",
      "No status found with that ID. : 866816280283807744\n",
      "No status found with that ID. : 861769973181624320\n",
      "No status found with that ID. : 856602993587888130\n",
      "No status found with that ID. : 851953902622658560\n",
      "No status found with that ID. : 845459076796616705\n",
      "No status found with that ID. : 844704788403113984\n",
      "No status found with that ID. : 842892208864923648\n",
      "No status found with that ID. : 837366284874571778\n",
      "No status found with that ID. : 837012587749474308\n",
      "No status found with that ID. : 829374341691346946\n",
      "No status found with that ID. : 827228250799742977\n",
      "No status found with that ID. : 812747805718642688\n",
      "No status found with that ID. : 802247111496568832\n",
      "No status found with that ID. : 775096608509886464\n",
      "No status found with that ID. : 770743923962707968\n",
      "No status found with that ID. : 754011816964026368\n",
      "No status found with that ID. : 680055455951884288\n"
     ]
    }
   ],
   "source": [
    "with open('tweet_json.txt', 'w') as file:\n",
    "    for tweet_id in twitter['tweet_id']:\n",
    "        try:\n",
    "            json.dump(api.get_status(tweet_id, wait_on_rate_limit=True)._json, file)\n",
    "            file.write('\\n')\n",
    "        except tweepy.TweepError as e:\n",
    "            print('{} : {}'.format(e.args[0][0]['message'], tweet_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "with open('tweet_json.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        tweet_dict = dict(json.loads(line))\n",
    "        tweet_id = tweet_dict['id']\n",
    "        favorite = tweet_dict['favorite_count']\n",
    "        retweet = tweet_dict['retweet_count']\n",
    "        \n",
    "        df.append({'tweet_id': tweet_id,\n",
    "                   'favorite_count': favorite,\n",
    "                   'retweet_count': retweet})\n",
    "        \n",
    "twitter_plus = pd.DataFrame(df, columns = ['tweet_id', 'favorite_count', 'retweet_count'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
